[tool.poetry]
name = "mistral-lora"
version = "0.1.0"
description = "Mistral 7B LoRA fine-tuning implementation"
authors = [
    "pbelinovich"
]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.10"
transformers = "^4.41.0"
datasets = "^2.19.1"
peft = "^0.11.1"
accelerate = "^0.29.3"
torch = "^2.3.0"
scipy = "^1.12.0"
tqdm = "^4.66.0"
psutil = "^5.9.0"
GPUtil = "^1.4.0"
tensorboard = "^2.16.0"
bitsandbytes = {version = "^0.46.0", platform = "linux"}

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
black = "^23.7.0"
isort = "^5.12.0"
flake8 = "^6.1.0"

[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"